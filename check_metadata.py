#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import gzip
import json
import os

def check_book_metadata(filepath):
    """ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ© Ù„Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬"""
    
    if not os.path.exists(filepath):
        print(f"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {filepath}")
        return
    
    try:
        with gzip.open(filepath, 'rt', encoding='utf-8') as f:
            data = json.load(f)
        
        print("ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„")
        print("=" * 60)
        
        # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        print("ğŸ“š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙƒØªØ§Ø¨:")
        print(f"   Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {data.get('title', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
        print(f"   Ù…Ø¹Ø±Ù Ø§Ù„Ø´Ø§Ù…Ù„Ø©: {data.get('shamela_id', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
        
        # Ø§Ù„Ù…Ø¤Ù„ÙÙˆÙ†
        authors = data.get('authors', [])
        if authors:
            print("âœï¸ Ø§Ù„Ù…Ø¤Ù„ÙÙˆÙ†:")
            for i, author in enumerate(authors, 1):
                if isinstance(author, dict):
                    author_name = author.get('name', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
                else:
                    author_name = str(author)
                print(f"   {i}. {author_name}")
        else:
            print("âœï¸ Ø§Ù„Ù…Ø¤Ù„Ù: ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
            
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø´Ø±
        print("\nğŸ“– Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø´Ø±:")
        publisher = data.get('publisher', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
        print(f"   Ø§Ù„Ù†Ø§Ø´Ø±: {publisher}")
        
        publication_year = data.get('publication_year', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
        print(f"   Ø³Ù†Ø© Ø§Ù„Ù†Ø´Ø±: {publication_year}")
        
        edition = data.get('edition', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
        if edition and edition != 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯':
            print(f"   Ø§Ù„Ø·Ø¨Ø¹Ø©: {edition}")
            
        edition_number = data.get('edition_number', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
        if edition_number and edition_number != 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯':
            print(f"   Ø±Ù‚Ù… Ø§Ù„Ø·Ø¨Ø¹Ø©: {edition_number}")
            
        edition_date_hijri = data.get('edition_date_hijri', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
        if edition_date_hijri and edition_date_hijri != 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯':
            print(f"   ØªØ§Ø±ÙŠØ® Ø§Ù„Ø·Ø¨Ø¹Ø© Ø§Ù„Ù‡Ø¬Ø±ÙŠ: {edition_date_hijri}")
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØµÙ†ÙŠÙ
        print(f"\nğŸ·ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØµÙ†ÙŠÙ:")
        book_section = data.get('book_section', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
        print(f"   Ø§Ù„Ù‚Ø³Ù…: {book_section}")
        
        categories = data.get('categories', [])
        if categories:
            print(f"   Ø§Ù„ÙØ¦Ø§Øª: {', '.join(categories)}")
        else:
            print(f"   Ø§Ù„ÙØ¦Ø§Øª: ØºÙŠØ± Ù…Ø­Ø¯Ø¯")
            
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª ÙˆØ§Ù„ÙØµÙˆÙ„
        page_count = data.get('page_count', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯') 
        volume_count = data.get('volume_count', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
        chapters = data.get('chapters', [])
        volumes = data.get('volumes', [])
        
        print(f"\nğŸ“Š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø­Ø¬Ù…:")
        print(f"   Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: {page_count}")
        print(f"   Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª: {volume_count}")
        print(f"   Ø¹Ø¯Ø¯ Ø§Ù„ÙØµÙˆÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©: {len(chapters)}")
        print(f"   Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©: {len(volumes)}")
        
        # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„ÙØµÙˆÙ„
        if chapters:
            print(f"\nğŸ“‘ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„ÙØµÙˆÙ„ (Ø£ÙˆÙ„ 5):")
            for i, chapter in enumerate(chapters[:5], 1):
                title = chapter.get('title', 'Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†')
                page_start = chapter.get('page_start', '?')
                page_end = chapter.get('page_end', '?')
                print(f"   {i}. {title} (Øµ {page_start}-{page_end})")
        
        # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡
        if volumes:
            print(f"\nğŸ“š Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ (Ø£ÙˆÙ„ 5):")
            for i, volume in enumerate(volumes[:5], 1):
                title = volume.get('title', f"Ø§Ù„Ø¬Ø²Ø¡ {volume.get('volume_number', i)}")
                page_start = volume.get('page_start', '?')
                page_end = volume.get('page_end', '?')
                print(f"   {i}. {title} (Øµ {page_start}-{page_end})")
        
        # Ø§Ù„ÙˆØµÙ
        description = data.get('description', '')
        if description and description.strip():
            print(f"\nğŸ“ ÙˆØµÙ Ø§Ù„ÙƒØªØ§Ø¨:")
            # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 300 Ø­Ø±Ù Ù…Ù† Ø§Ù„ÙˆØµÙ
            desc_preview = description[:300] + "..." if len(description) > 300 else description
            print(f"   {desc_preview}")
            
        # Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ØµØ¯Ø±
        source_url = data.get('source_url', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')
        print(f"\nğŸŒ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ØµØ¯Ø±: {source_url}")
        
        # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬
        metadata = data.get('extraction_metadata', {})
        if metadata:
            print("\nğŸ“ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬:")
            for key, value in metadata.items():
                print(f"   {key}: {value}")
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØµÙØ­Ø§Øª
        pages = data.get('pages', [])
        print(f"\nğŸ“„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØµÙØ­Ø§Øª:")
        print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙØ­Ø§Øª: {len(pages)}")
        
        if pages:
            # Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø­ØªÙˆÙ‰
            total_words = 0
            arabic_pages = 0
            empty_pages = 0
            
            for page in pages:
                content = page.get('content', '').strip()
                if content:
                    words = len(content.split())
                    total_words += words
                    
                    # ÙØ­Øµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
                    arabic_chars = sum(1 for c in content if '\u0600' <= c <= '\u06FF')
                    if arabic_chars > 10:  # Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ 10 Ø£Ø­Ø±Ù Ø¹Ø±Ø¨ÙŠØ©
                        arabic_pages += 1
                else:
                    empty_pages += 1
            
            print(f"   ØµÙØ­Ø§Øª Ø¨Ù…Ø­ØªÙˆÙ‰ Ø¹Ø±Ø¨ÙŠ: {arabic_pages}/{len(pages)}")
            print(f"   ØµÙØ­Ø§Øª ÙØ§Ø±ØºØ©: {empty_pages}/{len(pages)}")
            print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {total_words:,}")
            print(f"   Ù…ØªÙˆØ³Ø· Ø§Ù„ÙƒÙ„Ù…Ø§Øª/ØµÙØ­Ø©: {total_words/len(pages):.1f}")
        
        # Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        if pages:
            print("\nğŸ“– Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ (Ø£ÙˆÙ„ ØµÙØ­Ø©):")
            print("-" * 40)
            first_content = pages[0].get('content', '')
            preview = first_content[:300] + "..." if len(first_content) > 300 else first_content
            print(preview)
        
        # ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        print(f"\nğŸ” ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
        quality_score = 0
        max_score = 180  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù†Ù‚Ø§Ø· Ù„ØªØ´Ù…Ù„ Ø§Ù„ÙØµÙˆÙ„ ÙˆØ§Ù„Ø£Ø¬Ø²Ø§Ø¡
        checks = []
        
        # Ø§Ù„ÙØ­ÙˆØµØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (20 Ù†Ù‚Ø·Ø© Ù„ÙƒÙ„ ÙØ­Øµ)
        if data.get('title'):
            quality_score += 20
            checks.append("âœ… Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù…ÙˆØ¬ÙˆØ¯")
        else:
            checks.append("âŒ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù…ÙÙ‚ÙˆØ¯")
            
        if data.get('shamela_id'):
            quality_score += 20
            checks.append("âœ… Ù…Ø¹Ø±Ù Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ù…ÙˆØ¬ÙˆØ¯")
        else:
            checks.append("âŒ Ù…Ø¹Ø±Ù Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ù…ÙÙ‚ÙˆØ¯")
            
        if authors:
            quality_score += 20
            checks.append("âœ… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø¤Ù„Ù Ù…ÙˆØ¬ÙˆØ¯Ø©")
        else:
            checks.append("âŒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø¤Ù„Ù Ù…ÙÙ‚ÙˆØ¯Ø©")
            
        if pages:
            quality_score += 20
            checks.append(f"âœ… Ø§Ù„ØµÙØ­Ø§Øª Ù…ÙˆØ¬ÙˆØ¯Ø© ({len(pages)} ØµÙØ­Ø©)")
        else:
            checks.append("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙØ­Ø§Øª")
            
        if metadata:
            quality_score += 20
            checks.append("âœ… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆØ¬ÙˆØ¯Ø©")
        else:
            checks.append("âŒ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙÙ‚ÙˆØ¯Ø©")
            
        # Ø§Ù„ÙØ­ÙˆØµØ§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© (10 Ù†Ù‚Ø§Ø· Ù„ÙƒÙ„ ÙØ­Øµ)
        if data.get('publisher'):
            quality_score += 10
            checks.append("âœ… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø§Ø´Ø± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        else:
            checks.append("âš ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø§Ø´Ø± Ù…ÙÙ‚ÙˆØ¯Ø©")
            
        if data.get('description'):
            quality_score += 10
            checks.append("âœ… ÙˆØµÙ Ø§Ù„ÙƒØªØ§Ø¨ Ù…ÙˆØ¬ÙˆØ¯")
        else:
            checks.append("âš ï¸ ÙˆØµÙ Ø§Ù„ÙƒØªØ§Ø¨ Ù…ÙÙ‚ÙˆØ¯")
            
        if data.get('categories'):
            quality_score += 10
            checks.append("âœ… ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„ÙƒØªØ§Ø¨ Ù…ÙˆØ¬ÙˆØ¯Ø©")
        else:
            checks.append("âš ï¸ ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„ÙƒØªØ§Ø¨ Ù…ÙÙ‚ÙˆØ¯Ø©")
            
        if data.get('source_url'):
            quality_score += 10
            checks.append("âœ… Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ØµØ¯Ø± Ù…ÙˆØ¬ÙˆØ¯")
        else:
            checks.append("âš ï¸ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ØµØ¯Ø± Ù…ÙÙ‚ÙˆØ¯")
            
        if data.get('publication_year'):
            quality_score += 10
            checks.append("âœ… Ø³Ù†Ø© Ø§Ù„Ù†Ø´Ø± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        else:
            checks.append("âš ï¸ Ø³Ù†Ø© Ø§Ù„Ù†Ø´Ø± Ù…ÙÙ‚ÙˆØ¯Ø©")
            
        if data.get('book_section'):
            quality_score += 10
            checks.append("âœ… Ù‚Ø³Ù… Ø§Ù„ÙƒØªØ§Ø¨ Ù…ÙˆØ¬ÙˆØ¯")
        else:
            checks.append("âš ï¸ Ù‚Ø³Ù… Ø§Ù„ÙƒØªØ§Ø¨ Ù…ÙÙ‚ÙˆØ¯")
            
        # ÙØ­ÙˆØµØ§Øª Ø§Ù„ÙØµÙˆÙ„ ÙˆØ§Ù„Ø£Ø¬Ø²Ø§Ø¡ (10 Ù†Ù‚Ø§Ø· Ù„ÙƒÙ„ ÙØ­Øµ)
        if chapters:
            quality_score += 10
            checks.append(f"âœ… ÙØµÙˆÙ„ Ø§Ù„ÙƒØªØ§Ø¨ Ù…ÙˆØ¬ÙˆØ¯Ø© ({len(chapters)} ÙØµÙ„)")
        else:
            checks.append("âš ï¸ ÙØµÙˆÙ„ Ø§Ù„ÙƒØªØ§Ø¨ Ù…ÙÙ‚ÙˆØ¯Ø©")
            
        if volumes:
            quality_score += 10
            checks.append(f"âœ… Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ÙƒØªØ§Ø¨ Ù…ÙˆØ¬ÙˆØ¯Ø© ({len(volumes)} Ø¬Ø²Ø¡)")
        else:
            checks.append("âš ï¸ Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ÙƒØªØ§Ø¨ Ù…ÙÙ‚ÙˆØ¯Ø©")
        
        for check in checks:
            print(f"   {check}")
            
        quality_percentage = round((quality_score / max_score) * 100, 1)
        print(f"\nğŸ¯ Ø¯Ø±Ø¬Ø© Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©: {quality_percentage}% ({quality_score}/{max_score})")
        
        # ØªØµÙ†ÙŠÙ Ø§Ù„Ø¬ÙˆØ¯Ø©
        if quality_percentage >= 90:
            quality_rating = "ğŸ† Ù…Ù…ØªØ§Ø²Ø©"
        elif quality_percentage >= 75:
            quality_rating = "ğŸ¥‡ Ø¬ÙŠØ¯Ø© Ø¬Ø¯Ø§Ù‹"
        elif quality_percentage >= 60:
            quality_rating = "ğŸ¥ˆ Ø¬ÙŠØ¯Ø©"
        elif quality_percentage >= 45:
            quality_rating = "ğŸ¥‰ Ù…Ù‚Ø¨ÙˆÙ„Ø©"
        else:
            quality_rating = "âŒ Ø¶Ø¹ÙŠÙØ©"
            
        print(f"ğŸ“Š ØªØµÙ†ÙŠÙ Ø§Ù„Ø¬ÙˆØ¯Ø©: {quality_rating}")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")

if __name__ == "__main__":
    # ÙØ­Øµ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¶ØºÙˆØ·
    filepath = "ultra_reliable_books/ultra_reliable_book_12106_20250823_125421.json.gz"
    check_book_metadata(filepath)
