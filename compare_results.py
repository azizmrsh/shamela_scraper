#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù…Ù‚Ø§Ø±Ù†Ø© Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ… ÙˆØ§Ù„Ø¬Ø¯ÙŠØ¯ Ù„Ù„ÙƒØªØ§Ø¨ 43
Comparison of old vs new results for book 43
"""

import json

def compare_files():
    """Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ù„ÙÙŠÙ† ÙˆØ¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"""
    
    print("ğŸ” Ù…Ù‚Ø§Ø±Ù†Ø© Ù†ØªØ§Ø¦Ø¬ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒØªØ§Ø¨ 43")
    print("="*50)
    
    # Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ…
    try:
        with open('book43_100pages.json', 'r', encoding='utf-8') as f:
            old_data = json.load(f)
        
        old_total_words = sum(page.get('word_count', 0) for page in old_data.get('pages', []))
        old_first_page_length = len(old_data.get('pages', [{}])[0].get('content', '')) if old_data.get('pages') else 0
        
        print("ğŸ“„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ… (book43_100pages.json):")
        print(f"   â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {old_total_words}")
        print(f"   â€¢ Ø·ÙˆÙ„ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: {old_first_page_length} Ø­Ø±Ù")
        print(f"   â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„ÙƒÙ„Ù…Ø§Øª/ØµÙØ­Ø©: {old_total_words/100:.1f}")
        print(f"   â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø­Ø±Ù/ØµÙØ­Ø©: {old_first_page_length:.1f}")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ…: {e}")
        return
    
    # Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯
    try:
        with open('book43_100pages_fixed.json', 'r', encoding='utf-8') as f:
            new_data = json.load(f)
        
        new_total_words = sum(page.get('word_count', 0) for page in new_data.get('pages', []))
        new_first_page_length = len(new_data.get('pages', [{}])[0].get('content', '')) if new_data.get('pages') else 0
        
        print("\nğŸ“„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯ (book43_100pages_fixed.json):")
        print(f"   â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {new_total_words}")
        print(f"   â€¢ Ø·ÙˆÙ„ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: {new_first_page_length} Ø­Ø±Ù")
        print(f"   â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„ÙƒÙ„Ù…Ø§Øª/ØµÙØ­Ø©: {new_total_words/100:.1f}")
        print(f"   â€¢ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø­Ø±Ù/ØµÙØ­Ø©: {new_first_page_length:.1f}")
        
        # Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
        print("\nğŸ” Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©:")
        print("="*30)
        
        if new_total_words > old_total_words:
            improvement = ((new_total_words - old_total_words) / old_total_words) * 100
            print(f"âœ… ØªØ­Ø³Ù† Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: +{improvement:.1f}%")
        else:
            decline = ((old_total_words - new_total_words) / old_total_words) * 100
            print(f"âŒ Ø§Ù†Ø®ÙØ§Ø¶ Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: -{decline:.1f}%")
        
        if new_first_page_length > old_first_page_length:
            improvement = ((new_first_page_length - old_first_page_length) / old_first_page_length) * 100
            print(f"âœ… ØªØ­Ø³Ù† Ø·ÙˆÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: +{improvement:.1f}%")
        else:
            decline = ((old_first_page_length - new_first_page_length) / old_first_page_length) * 100
            print(f"âŒ Ø§Ù†Ø®ÙØ§Ø¶ Ø·ÙˆÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: -{decline:.1f}%")
        
        # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        print(f"\nğŸ“ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ (Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯):")
        print("-" * 50)
        first_page_content = new_data.get('pages', [{}])[0].get('content', '')[:200]
        print(first_page_content[:200])
        if len(first_page_content) > 200:
            print("...")
        
        # ÙØ­Øµ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        print(f"\nğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
        print("-" * 30)
        
        pages_with_content = len([p for p in new_data.get('pages', []) if p.get('word_count', 0) > 0])
        print(f"   â€¢ ØµÙØ­Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰: {pages_with_content}/100")
        print(f"   â€¢ Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­: {(pages_with_content/100)*100:.1f}%")
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©
        print(f"\nğŸ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø³Ù†Ø©:")
        print("-" * 25)
        print(f"   â€¢ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {new_data.get('title', 'ØºÙŠØ± Ù…ØªÙˆÙØ±')[:50]}")
        print(f"   â€¢ Ø§Ù„Ù…Ø¤Ù„Ù: {new_data.get('authors', [{'name': 'ØºÙŠØ± Ù…ØªÙˆÙØ±'}])[0].get('name', 'ØºÙŠØ± Ù…ØªÙˆÙØ±')}")
        print(f"   â€¢ Ø§Ù„Ù†Ø§Ø´Ø±: {new_data.get('publisher', {}).get('name', 'ØºÙŠØ± Ù…ØªÙˆÙØ±') if new_data.get('publisher') else 'ØºÙŠØ± Ù…ØªÙˆÙØ±'}")
        print(f"   â€¢ Ø§Ù„Ù‚Ø³Ù…: {new_data.get('book_section', {}).get('name', 'ØºÙŠØ± Ù…ØªÙˆÙØ±') if new_data.get('book_section') else 'ØºÙŠØ± Ù…ØªÙˆÙØ±'}")
        print(f"   â€¢ Ø¹Ø¯Ø¯ Ø§Ù„ÙØµÙˆÙ„: {len(new_data.get('index', []))}")
        print(f"   â€¢ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡: {len(new_data.get('volumes', []))}")
        print(f"   â€¢ Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ø§Ù„Ø£ØµÙ„ÙŠ: {'Ù†Ø¹Ù…' if new_data.get('has_original_pagination') else 'Ù„Ø§'}")
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯: {e}")
        return

if __name__ == "__main__":
    compare_files()
    print("\n" + "="*50)
    print("ğŸ‰ Ø§Ù†ØªÙ‡Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©!")
